{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Agents: Vacuum-cleaner World\n",
    "\n",
    "Implement a simulator environment for a vacuum-cleaner world and a set of intelligent agents.\n",
    "\n",
    "## PEAS description\n",
    "\n",
    "__Performance Measure:__ Each action costs 1. The performance is measured as the sum of the cost to clean the whole environment.\n",
    "\n",
    "__Environment:__ A room with $n \\times n$ squares where $n = 5$. Dirt is randomly placed on each square with probability $p = 0.2$. For simplicity, you can assume that the agent knows the size of the layout of the room (i.e., it knows n and where it starts).\n",
    "\n",
    "__Actuators:__ The agent can `clean` the current square or move to an adjacent square by going `north`, `east`, `west`, or `south`.\n",
    "\n",
    "__Sensors:__ Four bumper sensors, one for north`, `east`, `west`, and `south`; a dirt sensor reporting dirt in the current square.  \n",
    "\n",
    "The easiest implementation for the environment is to hold an 2-dimensional array to represent if squares are clean or dirty and to call the agent function in a loop untill all squares are clean or a predefined number of steps have been reached.\n",
    "\n",
    "## Define the agent program for a simple randomized agent\n",
    "\n",
    "The agent program is a function that gets sensor information (the current percepts) as the arguments. The arguments are:\n",
    "\n",
    "* A dictonary with boolean entries for the for bumper sensors `north`, `east`, `west`, `south`; not specified bumpers are assumed to be `False`. E.g., if the agent is on the north-west corner, `bumpers` gets `{\"north\" : True, \"west\" : True}` or if the agent is not close to a border then it gets `{}`.\n",
    "* The dirt sensor produces a boolean.\n",
    "\n",
    "The agent returns the chosen action as a string.\n",
    "\n",
    "Here is an example implementation for the agent program of a simple randomized agent:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "actions = [\"north\", \"east\", \"west\", \"south\", \"suck\"]\n",
    "\n",
    "\n",
    "def simple_randomized_agent(bumpers, dirty):\n",
    "    return random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'suck'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_randomized_agent({\"north\" : True}, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple environment example\n",
    "\n",
    "The environment is infinite in size (bumpers are always `False`) and every square is dirty. We run the agent for 10 times steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "west\n",
      "south\n",
      "east\n",
      "west\n",
      "south\n",
      "west\n",
      "south\n",
      "suck\n",
      "east\n",
      "suck\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(simple_randomized_agent({\"north\" : False, \"south\" : False, \"west\" : False, \"east\" : False}, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "_Submission Instructions:_ Use this notebook to prepare your submission. Complete this section with your code and results. You can use Markdown blocks for your description, comments in the code and use mathplotlib to produce charts. If you use external code files then you can include them with \n",
    "\n",
    "```\n",
    "from notebook import psource\n",
    "psource(\"your_file.py\")\n",
    "```\n",
    "\n",
    "_Note:_ Try to keep the code simple! In this couse, we want to learn about the algorithms and we often do not need to use object-oriented design. \n",
    "\n",
    "\n",
    "## Task 1: Implement a simulation environment\n",
    "\n",
    "Your environment simulator needs to create squares, make some dirty, and proivde the agent function with the sensor inputs. The environment needs to evaluate the performance measure. It needs to track the agent's actions until all dirty squares are clean and count the number of actions it takes the agent to complete the task.\n",
    "\n",
    "The simulation environment needs to work with the simple randomized agent program from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:  Implement a simple reflex agent\n",
    "\n",
    "The simple reflex agent randomly walks around but reacts to the bumper sensor by not bumping into the wall and to dirt with sucking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement a model-based reflex agent \n",
    "\n",
    "This agent keeps track of the location and remembers where it has cleaned. Assume the agent knows how many squares the room has and where it starts. It can now use more advanced navigation.\n",
    "\n",
    "How will your agent perform if it is put into a larger room, if the room contains obstacles, or it starts in a random square?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Simulation study\n",
    "\n",
    "Compare the performance of the agents using different size environments. E.g., $5 \\times 5$, $10 \\times 10$ and\n",
    "$100 \\times 100$. Use at least 100 random runs for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus tasks\n",
    "\n",
    "* __Obstacles:__ Add random obstacle squares that also trigger the bumper sensor. The agent does not know where the obstacles are. How does this change the performance?\n",
    "* __Unknown environment with obstacles:__ The agent does not know how large the environment is, where it starts or where the obstacles are.\n",
    "* __Utility-based agent:__ Change the environment, so each square has a fixed probability of getting dirty again. Give this information to the agent (as a 2-dimensional array of probabilities). Cleaning one dirty square produces the utility of 1. Implement a utility-based agent that maximizes the expected utility over a time horizon of 10000 time steps. This is very tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
